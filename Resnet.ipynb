{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import Model\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.layers import Dropout,GlobalAveragePooling2D,Dense\n",
    "from keras import applications as apps\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler,TensorBoard\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/ankan/Projects/sleeve/weights/sleeves'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = os.listdir('/home/ankan/Projects/sleeve/data_sleeves/Resized_Data/Data/train/')\n",
    "DATA_DIR1 = '/home/ankan/Projects/sleeve/data_sleeves/Resized_Data/Data/'\n",
    "train_dir = os.path.join(DATA_DIR1, 'train')\n",
    "test_dir = os.path.join(DATA_DIR1, 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_NB_EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nb_files(directory):\n",
    "  \"\"\"Get number of files by searching directory recursively\"\"\"\n",
    "  if not os.path.exists(directory):\n",
    "    return 0\n",
    "  cnt = 0\n",
    "  for r, dirs, files in os.walk(directory):\n",
    "    for dr in dirs:\n",
    "      cnt += len(glob.glob(os.path.join(r, dr + \"/*\")))\n",
    "  return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossLearningRateScheduler(keras.callbacks.History):\n",
    "\n",
    "    def __init__(self, base_lr, lookback_epochs, spike_epochs = None, spike_multiple = 10, decay_threshold = 0.002, decay_multiple = 0.5, loss_type = 'val_loss'):\n",
    "\n",
    "        super(LossLearningRateScheduler, self).__init__()\n",
    "\n",
    "        self.base_lr = base_lr\n",
    "        self.lookback_epochs = lookback_epochs\n",
    "        self.spike_epochs = spike_epochs\n",
    "        self.spike_multiple = spike_multiple\n",
    "        self.decay_threshold = decay_threshold\n",
    "        self.decay_multiple = decay_multiple\n",
    "        self.loss_type = loss_type\n",
    "\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        \n",
    "        if len(self.epoch) > self.lookback_epochs:\n",
    "\n",
    "            current_lr = K.get_value(self.model.optimizer.lr)\n",
    "\n",
    "            target_loss = self.history[self.loss_type] \n",
    "\n",
    "            print('loss1: ',target_loss[-int(self.lookback_epochs)])\n",
    "            print('loss2: ',target_loss[-1])\n",
    "            \n",
    "\n",
    "            loss_diff =  target_loss[-int(self.lookback_epochs)] - target_loss[-1]\n",
    "            \n",
    "            print('loss1-loss2: ',loss_diff)\n",
    "\n",
    "            if loss_diff <= np.abs(target_loss[-1]) * (self.decay_threshold * self.lookback_epochs):\n",
    "\n",
    "                print(' '.join(('Changing learning rate from', str(current_lr), 'to', str(current_lr * self.decay_multiple))))\n",
    "                K.set_value(self.model.optimizer.lr, current_lr * self.decay_multiple)\n",
    "                current_lr = current_lr * self.decay_multiple\n",
    "\n",
    "            else:\n",
    "\n",
    "                print(' '.join(('Learning rate:', str(current_lr))))\n",
    "\n",
    "            if self.spike_epochs is not None and len(self.epoch) in self.spike_epochs:\n",
    "                print(' '.join(('Spiking learning rate from', str(current_lr), 'to', str(current_lr * self.spike_multiple))))\n",
    "                K.set_value(self.model.optimizer.lr, current_lr * self.spike_multiple)\n",
    "\n",
    "        else:\n",
    "\n",
    "            print(' '.join(('Setting learning rate to', str(self.base_lr))))\n",
    "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
    "\n",
    "\n",
    "        return K.get_value(self.model.optimizer.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    batch_size = 64\n",
    "    num_classes = len(glob.glob(train_dir + \"/*\"))\n",
    "    steps_train = (get_nb_files(train_dir)/batch_size)\n",
    "    steps_test = (get_nb_files(test_dir)/batch_size)\n",
    "\n",
    "    base_model = apps.resnet50.ResNet50(weights='imagenet',input_shape=(224,224,3),include_top=False)\n",
    "    ppf = apps.resnet50.preprocess_input\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1024,activation='relu')(x)\n",
    "    pred = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=pred)\n",
    "\n",
    "    train_gen = ImageDataGenerator(\n",
    "        preprocessing_function=ppf)\n",
    "\n",
    "    train_gen = train_gen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(224,224),\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    test_gen = ImageDataGenerator(\n",
    "        preprocessing_function=ppf)\n",
    "\n",
    "    test_gen = test_gen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(224,224),\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    for i, layer in enumerate(base_model.layers):\n",
    "        layer.trainable = False \n",
    "    \n",
    "    model.compile(optimizer=Adam(lr=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    mod_wt_path = path+'/best_weights.hdf5'\n",
    "    best_wts_callback = keras.callbacks.ModelCheckpoint(mod_wt_path, save_weights_only=True, save_best_only=True)\n",
    "    history2 = model.fit_generator(train_gen,steps_per_epoch=steps_train,\n",
    "                               epochs=ft_NB_EPOCHS,validation_data=test_gen,\n",
    "                               validation_steps=steps_test,class_weight='auto',callbacks=[best_wts_callback,LossLearningRateScheduler(base_lr = 0.0001, lookback_epochs = 3)])\n",
    "    model.load_weights(mod_wt_path)\n",
    "    model.save(path+'/multigpu_128batchsize5stagefull.hdf5')\n",
    "    \n",
    "    acc_history = history2.history['acc']\n",
    "    numpy_acc_history = np.array(acc_history)\n",
    "\n",
    "    val_acc_history = history2.history['val_acc']\n",
    "    numpy_loss_history = np.array(val_acc_history)\n",
    "\n",
    "    loss_history = history2.history['loss']\n",
    "    numpy_history3 = np.array(loss_history)\n",
    "\n",
    "    val_loss_history = history2.history['val_loss']\n",
    "    numpy_history4 = np.array(val_loss_history)\n",
    "\n",
    "    df = pd.DataFrame(index=range(len(numpy_acc_history)))\n",
    "    df.loc[:,'acc'] = numpy_acc_history\n",
    "    df.loc[:,'val_acc'] = numpy_loss_history\n",
    "    df.loc[:,'loss'] = numpy_history3\n",
    "    df.loc[:,'val_loss'] = numpy_history4\n",
    "    df.to_csv(path+\"/crop_avgfn_history_fn1_2004\"+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1221 images belonging to 4 classes.\n",
      "Found 152 images belonging to 4 classes.\n",
      "Epoch 1/30\n",
      "Setting learning rate to 0.0001\n",
      "20/19 [===============================] - 480s 24s/step - loss: 1.3938 - acc: 0.3878 - val_loss: 1.1583 - val_acc: 0.5000\n",
      "Epoch 2/30\n",
      "Setting learning rate to 0.0001\n",
      "20/19 [===============================] - 456s 23s/step - loss: 1.0443 - acc: 0.5524 - val_loss: 1.0002 - val_acc: 0.5789\n",
      "Epoch 3/30\n",
      "Setting learning rate to 0.0001\n",
      "20/19 [===============================] - 432s 22s/step - loss: 0.8597 - acc: 0.6592 - val_loss: 0.8910 - val_acc: 0.6645\n",
      "Epoch 4/30\n",
      "Setting learning rate to 0.0001\n",
      "20/19 [===============================] - 452s 23s/step - loss: 0.7786 - acc: 0.6919 - val_loss: 0.8290 - val_acc: 0.6250\n",
      "Epoch 5/30\n",
      "loss1:  1.0002056454357349\n",
      "loss2:  0.8290185677377802\n",
      "loss1-loss2:  0.17118707769795471\n",
      "Learning rate: 1e-04\n",
      "20/19 [===============================] - 455s 23s/step - loss: 0.7161 - acc: 0.7306 - val_loss: 0.8646 - val_acc: 0.5658\n",
      "Epoch 6/30\n",
      "loss1:  0.8909974788364611\n",
      "loss2:  0.8645575266135367\n",
      "loss1-loss2:  0.02643995222292439\n",
      "Learning rate: 1e-04\n",
      "20/19 [===============================] - 419s 21s/step - loss: 0.7490 - acc: 0.7051 - val_loss: 0.7646 - val_acc: 0.6974\n",
      "Epoch 7/30\n",
      "loss1:  0.8290185677377802\n",
      "loss2:  0.764552514804037\n",
      "loss1-loss2:  0.06446605293374319\n",
      "Learning rate: 1e-04\n",
      "20/19 [===============================] - 417s 21s/step - loss: 0.6756 - acc: 0.7461 - val_loss: 0.7232 - val_acc: 0.7237\n",
      "Epoch 8/30\n",
      "loss1:  0.8645575266135367\n",
      "loss2:  0.7232476786563271\n",
      "loss1-loss2:  0.14130984795720958\n",
      "Learning rate: 1e-04\n",
      "20/19 [===============================] - 482s 24s/step - loss: 0.6396 - acc: 0.7547 - val_loss: 0.7071 - val_acc: 0.7368\n",
      "Epoch 9/30\n",
      "loss1:  0.764552514804037\n",
      "loss2:  0.707104913498226\n",
      "loss1-loss2:  0.05744760130581095\n",
      "Learning rate: 1e-04\n",
      "20/19 [===============================] - 495s 25s/step - loss: 0.5878 - acc: 0.7837 - val_loss: 0.6754 - val_acc: 0.7566\n",
      "Epoch 10/30\n",
      "loss1:  0.7232476786563271\n",
      "loss2:  0.6754455331124758\n",
      "loss1-loss2:  0.047802145543851315\n",
      "Learning rate: 1e-04\n",
      "20/19 [===============================] - 514s 26s/step - loss: 0.5995 - acc: 0.7630 - val_loss: 0.6714 - val_acc: 0.7566\n",
      "Epoch 11/30\n",
      "loss1:  0.707104913498226\n",
      "loss2:  0.6714195954172235\n",
      "loss1-loss2:  0.035685318081002504\n",
      "Learning rate: 1e-04\n",
      "20/19 [===============================] - 501s 25s/step - loss: 0.5578 - acc: 0.7908 - val_loss: 0.7438 - val_acc: 0.6908\n",
      "Epoch 12/30\n",
      "loss1:  0.6754455331124758\n",
      "loss2:  0.743781936796088\n",
      "loss1-loss2:  -0.06833640368361216\n",
      "Changing learning rate from 1e-04 to 4.999999873689376e-05\n",
      "20/19 [===============================] - 495s 25s/step - loss: 0.5337 - acc: 0.8056 - val_loss: 0.7134 - val_acc: 0.7171\n",
      "Epoch 13/30\n",
      "loss1:  0.6714195954172235\n",
      "loss2:  0.713358853992663\n",
      "loss1-loss2:  -0.04193925857543945\n",
      "Changing learning rate from 5e-05 to 2.499999936844688e-05\n",
      "20/19 [===============================] - 498s 25s/step - loss: 0.4904 - acc: 0.8191 - val_loss: 0.7098 - val_acc: 0.7303\n",
      "Epoch 14/30\n",
      "loss1:  0.743781936796088\n",
      "loss2:  0.709797203540802\n",
      "loss1-loss2:  0.03398473325528595\n",
      "Learning rate: 2.5e-05\n",
      "20/19 [===============================] - 419s 21s/step - loss: 0.5197 - acc: 0.7969 - val_loss: 0.7129 - val_acc: 0.7105\n",
      "Epoch 15/30\n",
      "loss1:  0.713358853992663\n",
      "loss2:  0.7128816184244657\n",
      "loss1-loss2:  0.0004772355681972318\n",
      "Changing learning rate from 2.5e-05 to 1.249999968422344e-05\n",
      "20/19 [===============================] - 417s 21s/step - loss: 0.5450 - acc: 0.7812 - val_loss: 0.7090 - val_acc: 0.6974\n",
      "Epoch 16/30\n",
      "loss1:  0.709797203540802\n",
      "loss2:  0.7089537350754989\n",
      "loss1-loss2:  0.0008434684653031432\n",
      "Changing learning rate from 1.25e-05 to 6.24999984211172e-06\n",
      "20/19 [===============================] - 417s 21s/step - loss: 0.5213 - acc: 0.7992 - val_loss: 0.7026 - val_acc: 0.7171\n",
      "Epoch 17/30\n",
      "loss1:  0.7128816184244657\n",
      "loss2:  0.7025707677790993\n",
      "loss1-loss2:  0.01031085064536641\n",
      "Learning rate: 6.25e-06\n",
      "20/19 [===============================] - 416s 21s/step - loss: 0.5068 - acc: 0.8211 - val_loss: 0.7040 - val_acc: 0.7171\n",
      "Epoch 18/30\n",
      "loss1:  0.7089537350754989\n",
      "loss2:  0.7039974896531356\n",
      "loss1-loss2:  0.004956245422363281\n",
      "Learning rate: 6.25e-06\n",
      "20/19 [===============================] - 417s 21s/step - loss: 0.4943 - acc: 0.8230 - val_loss: 0.7063 - val_acc: 0.7171\n",
      "Epoch 19/30\n",
      "loss1:  0.7025707677790993\n",
      "loss2:  0.7063488740670053\n",
      "loss1-loss2:  -0.00377810628790598\n",
      "Changing learning rate from 6.25e-06 to 3.12499992105586e-06\n",
      "20/19 [===============================] - 416s 21s/step - loss: 0.4899 - acc: 0.8199 - val_loss: 0.7146 - val_acc: 0.7105\n",
      "Epoch 20/30\n",
      "loss1:  0.7039974896531356\n",
      "loss2:  0.7145720406582481\n",
      "loss1-loss2:  -0.010574551005112509\n",
      "Changing learning rate from 3.125e-06 to 1.56249996052793e-06\n",
      "20/19 [===============================] - 420s 21s/step - loss: 0.4859 - acc: 0.8094 - val_loss: 0.7139 - val_acc: 0.7105\n",
      "Epoch 21/30\n",
      "loss1:  0.7063488740670053\n",
      "loss2:  0.7138724076120477\n",
      "loss1-loss2:  -0.007523533545042427\n",
      "Changing learning rate from 1.5625e-06 to 7.81249980263965e-07\n",
      "20/19 [===============================] - 418s 21s/step - loss: 0.4921 - acc: 0.8006 - val_loss: 0.7134 - val_acc: 0.7171\n",
      "Epoch 22/30\n",
      "loss1:  0.7145720406582481\n",
      "loss2:  0.7134021677468952\n",
      "loss1-loss2:  0.0011698729113528428\n",
      "Changing learning rate from 7.8125e-07 to 3.906249901319825e-07\n",
      "20/19 [===============================] - 419s 21s/step - loss: 0.4890 - acc: 0.8230 - val_loss: 0.7120 - val_acc: 0.7237\n",
      "Epoch 23/30\n",
      "loss1:  0.7138724076120477\n",
      "loss2:  0.7120145527940047\n",
      "loss1-loss2:  0.0018578548180430143\n",
      "Changing learning rate from 3.90625e-07 to 1.9531249506599124e-07\n",
      "20/19 [===============================] - 417s 21s/step - loss: 0.4723 - acc: 0.8299 - val_loss: 0.7119 - val_acc: 0.7237\n",
      "Epoch 24/30\n",
      "loss1:  0.7134021677468952\n",
      "loss2:  0.7118666077914991\n",
      "loss1-loss2:  0.0015355599553961152\n",
      "Changing learning rate from 1.953125e-07 to 9.765624753299562e-08\n",
      "20/19 [===============================] - 419s 21s/step - loss: 0.4770 - acc: 0.8277 - val_loss: 0.7117 - val_acc: 0.7237\n",
      "Epoch 25/30\n",
      "loss1:  0.7120145527940047\n",
      "loss2:  0.7117303421622828\n",
      "loss1-loss2:  0.00028421063172190397\n",
      "Changing learning rate from 9.765625e-08 to 4.882812376649781e-08\n",
      "20/19 [===============================] - 417s 21s/step - loss: 0.5233 - acc: 0.7928 - val_loss: 0.7117 - val_acc: 0.7237\n",
      "Epoch 26/30\n",
      "loss1:  0.7118666077914991\n",
      "loss2:  0.7116563853464628\n",
      "loss1-loss2:  0.00021022244503632326\n",
      "Changing learning rate from 4.8828124e-08 to 2.4414061883248905e-08\n",
      "20/19 [===============================] - 417s 21s/step - loss: 0.5498 - acc: 0.7871 - val_loss: 0.7115 - val_acc: 0.7237\n",
      "Epoch 27/30\n",
      "loss1:  0.7117303421622828\n",
      "loss2:  0.7115477762724224\n",
      "loss1-loss2:  0.00018256588986043099\n",
      "Changing learning rate from 2.4414062e-08 to 1.2207030941624453e-08\n",
      "20/19 [===============================] - 425s 21s/step - loss: 0.4777 - acc: 0.8269 - val_loss: 0.7115 - val_acc: 0.7237\n",
      "Epoch 28/30\n",
      "loss1:  0.7116563853464628\n",
      "loss2:  0.7115347479519091\n",
      "loss1-loss2:  0.0001216373945537308\n",
      "Changing learning rate from 1.2207031e-08 to 6.103515470812226e-09\n",
      "20/19 [===============================] - 419s 21s/step - loss: 0.5224 - acc: 0.7967 - val_loss: 0.7115 - val_acc: 0.7237\n",
      "Epoch 29/30\n",
      "loss1:  0.7115477762724224\n",
      "loss2:  0.7115208192875511\n",
      "loss1-loss2:  2.6956984871318035e-05\n",
      "Changing learning rate from 6.1035155e-09 to 3.051757735406113e-09\n",
      "20/19 [===============================] - 417s 21s/step - loss: 0.4982 - acc: 0.8078 - val_loss: 0.7115 - val_acc: 0.7237\n",
      "Epoch 30/30\n",
      "loss1:  0.7115347479519091\n",
      "loss2:  0.7115188491971869\n",
      "loss1-loss2:  1.5898754722187824e-05\n",
      "Changing learning rate from 3.0517577e-09 to 1.5258788677030566e-09\n",
      "20/19 [===============================] - 417s 21s/step - loss: 0.4955 - acc: 0.8203 - val_loss: 0.7115 - val_acc: 0.7237\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
